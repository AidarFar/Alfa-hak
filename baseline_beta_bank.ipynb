{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":8139281,"datasetId":4812001,"databundleVersionId":8259799},{"sourceType":"datasetVersion","sourceId":8117510,"datasetId":4791490,"databundleVersionId":8236384},{"sourceType":"datasetVersion","sourceId":8150612,"datasetId":4816160,"databundleVersionId":8271815}],"dockerImageVersionId":30683,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Cодержание:\n* [First Bullet Header](#first-bullet)\n* [Second Bullet Header](#second-bullet)","metadata":{"id":"4jh_q-9jEhtx"}},{"cell_type":"markdown","source":"# Команда: Бета Банк\n\n\n**Цель:** Создать CLTV модель, которая будет выдавать вероятности перехода в каждый из 17 продуктовых кластеров в течение 12 месяцев.\n\nАльфа-Банком предоставлены следующие **данные**:\n\n-   Тренировочный датасет `train_data.pqt` содержит данные о 200 000 клиентах банка и их целевых переменных за три последовательных месяца (month_1, month_2, month_3)\n-   Тестовый датасет `test_data.pqt` записи о 100 000 клиентах за 3 последовательных месяца (month_4, month_5, month_6)\n   \n-   Продуктовый кластер, в котором клиент будет находится через год - `end_cluster`. Необходимо получить вероятности перехода клиента в продуктовые кластеры для последнего месяца (month_6).\n\n  \n-    Метрикой качества выступает **ROC-AUC**.\n\nДанные о клиентах и масскированы.","metadata":{"id":"FpZmUQ0iEht0"}},{"cell_type":"markdown","source":"## Подключение модулей","metadata":{"id":"PPHzVdzXEht1"}},{"cell_type":"code","source":"!pip install catboost","metadata":{"execution":{"iopub.status.busy":"2024-04-18T05:53:57.481556Z","iopub.execute_input":"2024-04-18T05:53:57.482327Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: catboost in /opt/conda/lib/python3.10/site-packages (1.2.3)\nRequirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost) (0.20.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from catboost) (3.7.5)\nRequirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from catboost) (1.26.4)\nRequirement already satisfied: pandas>=0.24 in /opt/conda/lib/python3.10/site-packages (from catboost) (2.1.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from catboost) (1.11.4)\nRequirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost) (5.18.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost) (1.16.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2023.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (3.1.1)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost) (8.2.3)\n","output_type":"stream"}]},{"cell_type":"code","source":"# работа с ОС\nimport os\nimport warnings\nimport time\n# работа с данными\nimport json\nimport numpy as np\nimport pandas as pd\nfrom typing import Optional, Dict, Tuple\n# визуализация\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display, HTML\nfrom matplotlib.ticker import MaxNLocator\n# работа с ML\nfrom sklearn.utils import resample\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n# модели машинного обучения\n# import optuna\nfrom catboost import CatBoostClassifier, Pool\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import StackingClassifier, RandomForestClassifier, ExtraTreesClassifier\n# обработка ошибок\nfrom pyarrow import ArrowInvalid\n# настройка среды выполнения\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.float_format', '{:.4f}'.format)\npd.set_option('display.max_rows', 93)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Загрузка и изучение данных","metadata":{"id":"mszUZuLKEht3"}},{"cell_type":"code","source":"def read_df(filepath: str) -> Optional[pd.DataFrame]:\n    \"\"\"\n    Функция для чтения датасета по указанному пути\n\n    args:\n    filepath (str) - путь к файлу .pqt / .parquet\n\n    return:\n    датасет в формате pd.DataFrame, если найден файл по указанному пути\n    \"\"\"\n    if os.path.exists(filepath):\n        try:\n            result: pd.DataFrame = pd.read_parquet(filepath, engine='auto')\n            print(f\"Файл {filepath} успешно открыт\")\n            return result\n        except ArrowInvalid:\n            print(\"Неверный тип файла. Поддерживаемый - .pqt или .parquet\")\n            return\n    print(f\"Файл не найден по пути {filepath}\")\n    return","metadata":{"id":"yS_uNqUJEht3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"id":"NWuN8YclEwar","outputId":"d87d1c18-b17b-479b-be84-8b220ec03cfb","colab":{"base_uri":"https://localhost:8080/"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Путь до файла train_df\npath_train_df = \"/kaggle/input/alfa-hackaton/train_data.pqt\"\n# Путь до файла test_df\npath_test_df = \"/kaggle/input/alfa-hackaton/test_data.pqt\"\n\n# чтение файлов\ntrain_df = read_df(path_train_df)\ntest_df = read_df(path_test_df)\n\n# объединение файлов\ndf = pd.concat([train_df, test_df], ignore_index=True)\n\n# меняем в test_df нумирацию месяца\ndf['date'] = df['date'].replace({'month_4': 'month_1', 'month_5': 'month_2', 'month_6': 'month_3'})\n\n\ndisplay(train_df.head(2))\ndisplay(test_df.head(2))","metadata":{"id":"nRZCvdWvEht3","outputId":"4b50a549-5aca-4dcd-ce92-696b62ac0633","colab":{"base_uri":"https://localhost:8080/"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Базовый анализ данных","metadata":{}},{"cell_type":"code","source":"print(f\"Количество записей в тренировочных данных: {len(train_df)}\")\nprint(f\"Количество записей в тестовых данных: {len(test_df)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"В тестовой выборке у 30040 клиентов нет информации по 4 месяцу.","metadata":{}},{"cell_type":"code","source":"df.dtypes.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Признаки по большей части представляют собой числа с плавающей точкой, также присутствует 11 категориальных признаков, их необходимо закодировать.","metadata":{}},{"cell_type":"code","source":"df[df.duplicated(subset=df.columns.difference(['id']), keep=False)].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Дубликаты записей есть. Удалние их в train не приводит к успеху.","metadata":{}},{"cell_type":"code","source":"df['start_cluster'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Распределение основного признака (начального кластера, из которого будет осуществляться переход в конечный кластер, являющийся целевой переменной) сильно дизбалансное.","metadata":{}},{"cell_type":"code","source":"df['end_cluster'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Распределение целевой переменной также сильно дизбалансное. В нашем решении, мы пробовали обучать на дизабалансом, баланс по мажорному классу, использовали SMOKE, баланс с указанием конкретного числа признаков, баланс к среднему числу признаков. Лучше всего работает на дизбалансном.","metadata":{}},{"cell_type":"markdown","source":"## Предобработка данных","metadata":{"id":"QBmDSwCIEht4"}},{"cell_type":"markdown","source":"### Восстановление численных признаков","metadata":{"id":"sHn0yjXxEht4"}},{"cell_type":"code","source":"numeric_cols = df.drop(columns=['id']).select_dtypes(include=['number']).columns.tolist()\nfor col in numeric_cols:\n    # получением минимального возможного значения признака\n    mean_val = df[col].mean()\n    # заполнение пропущенных значений минимальным значением признака\n    df[col].fillna(mean_val, inplace=True)","metadata":{"id":"gKGeeJLcEht4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Для начала были восстановленны пропущенные записи у всех численных признаков средними значениями признака. Пробовали также среднии с учетом категориального признака okved. Лучшее работает 1 способ.","metadata":{}},{"cell_type":"code","source":"df['avg_a_oper_1m'] = df['sum_a_oper_1m'] / df['cnt_a_oper_1m']\ndf['avg_b_oper_1m'] = df['sum_b_oper_1m'] / df['cnt_b_oper_1m']\ndf['avg_c_oper_1m'] = df['sum_c_oper_1m'] / df['cnt_c_oper_1m']\n\ndf['avg_deb_d_oper_1m'] = df['sum_deb_d_oper_1m'] / df['cnt_deb_d_oper_1m']\ndf['avg_cred_d_oper_1m'] = df['sum_cred_d_oper_1m'] / df['cnt_cred_d_oper_1m']\n\ndf['avg_deb_e_oper_1m'] = df['sum_deb_e_oper_1m'] / df['cnt_deb_e_oper_1m']\ndf['avg_cred_e_oper_1m'] = df['sum_cred_e_oper_1m'] / df['cnt_cred_e_oper_1m']\n\n\ndf['avg_deb_f_oper_1m'] = df['sum_deb_f_oper_1m'] / df['cnt_deb_f_oper_1m']\ndf['avg_cred_f_oper_1m'] = df['sum_cred_f_oper_1m'] / df['cnt_cred_f_oper_1m']\n\ndf['avg_deb_g_oper_1m'] = df['sum_deb_g_oper_1m'] / df['cnt_deb_g_oper_1m']\ndf['avg_cred_g_oper_1m'] = df['sum_cred_g_oper_1m'] / df['cnt_cred_g_oper_1m']\n\ndf['avg_deb_h_oper_1m'] = df['sum_deb_h_oper_1m'] / df['cnt_deb_h_oper_1m']\ndf['avg_cred_h_oper_1m'] = df['sum_cred_h_oper_1m'] / df['cnt_cred_h_oper_1m']\n\n\ndf['avg_a_oper_3m'] = df['sum_a_oper_3m'] / df['cnt_a_oper_3m']\ndf['avg_b_oper_3m'] = df['sum_b_oper_3m'] / df['cnt_b_oper_3m']\ndf['avg_c_oper_3m'] = df['sum_c_oper_3m'] / df['cnt_c_oper_3m']\n\ndf['avg_deb_d_oper_3m'] = df['sum_deb_d_oper_3m'] / df['cnt_deb_d_oper_3m']\ndf['avg_cred_d_oper_3m'] = df['sum_cred_d_oper_3m'] / df['cnt_cred_d_oper_3m']\n\ndf['avg_deb_e_oper_3m'] = df['sum_deb_e_oper_3m'] / df['cnt_deb_e_oper_3m']\ndf['avg_cred_e_oper_3m'] = df['sum_cred_e_oper_3m'] / df['cnt_cred_e_oper_3m']\n\ndf['avg_deb_f_oper_3m'] = df['sum_deb_f_oper_3m'] / df['cnt_deb_f_oper_3m']\ndf['avg_cred_f_oper_3m'] = df['sum_cred_f_oper_3m'] / df['cnt_cred_f_oper_3m']\n\ndf['avg_deb_g_oper_3m'] = df['sum_deb_g_oper_3m'] / df['cnt_deb_g_oper_3m']\ndf['avg_cred_g_oper_3m'] = df['sum_cred_g_oper_3m'] / df['cnt_cred_g_oper_3m']\n\ndf['avg_deb_h_oper_3m'] = df['sum_deb_h_oper_3m'] / df['cnt_deb_h_oper_3m']\ndf['avg_cred_h_oper_3m'] = df['sum_cred_h_oper_3m'] / df['cnt_cred_h_oper_3m']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Введение дополнительного признака \"среднего\" по каждой операции каждого клиента за каждый месяц. Так как признак суммы имеет большое количество одного уникального значения. ","metadata":{}},{"cell_type":"code","source":"def restore_cal(x: pd.Series) -> pd.Series:\n    \"\"\"\n    Функция восстановления категориального признака последним значением для\n    конкретного клиента\n\n    args:\n    x (pd.Series) - значения рассматриваемого признака в группе\n\n    return:\n    Возвращается группа с восстановленным пропущенным значением\n    \"\"\"\n    # если есть пропущеные значения\n    if x.isna().any() and not x.isna().all():\n        # заполняем пропущенное значение последним в группе\n        return x.fillna(x.dropna().iloc[-1])\n    # если все пропуски, заполняем 'missing'\n    elif x.isna().all():\n        return x.fillna('missing')\n    # если нет пропусков, возвращаем исходную группу\n    return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_columns_to_restore = ['channel_code', 'city', 'city_type', 'ogrn_month', 'ogrn_year', 'okved', 'segment']\nfor column in cat_columns_to_restore:\n    start_time = time.time()\n    df[column] = df.groupby('id')[column].apply(restore_cal).reset_index()[column]\n    end_time = time.time()\n    print(f\"Колонка - {column} - восстановлена за {end_time - start_time}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"У клиента категорильный признак такой же как и в других месяцах, кроме start_cluster и end_cluster.\nОтсюда следует, что пропущенные категориальные признаки можно восстановить последним значением признака для клиента. Если вообще нету информации создаем класс - missing.\n\nШанс 3 одинаковых категориальных признаков.\n\nchannel_code - 99.98309597261547 %\n\ncity - 99.74894658491661 %\n\ncity_type - 99.315048321069 %\n\nindex_city_code - 99.59118119433495 %\n\nogrn_month - 99.9894837655631 %\n\nogrn_year - 99.98835702615914 %\n\nokved - 99.61698352916413 %\n\nsegment - 99.80287835153736 %\n\nstart_cluster - 80.04299999999999 %\n\nend_cluster - 88.4095 %\n\n\n\n\nЕще из интересной статистики.\n\nШанс, что клиент остаётся в том же кластере с 2 по 3 месяц: 93.3%","metadata":{}},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Создание таблицы с 3 месяцами","metadata":{}},{"cell_type":"code","source":"cat_cols = [\n    \"channel_code\", \"city\", \"city_type\",\n    \"okved\", \"segment\", \"ogrn_month\", \"ogrn_year\",\n]\ncat_cols_month_1 = [f'{col}_month_1' for col in cat_cols]\ncat_cols_month_2 = [f'{col}_month_2' for col in cat_cols]\n# сводная таблица по клиентам и месяцам\ndf = df.pivot_table(index='id', columns='date', aggfunc='first')\ndf.columns = [f'{col[0]}_{col[1]}' for col in df.columns]\ndf.reset_index(inplace=True)\ndf = df.drop(\n    columns=['end_cluster_month_1', 'end_cluster_month_2'] + cat_cols_month_1 + cat_cols_month_2,\n    axis=0)\ncategorical_columns = df.select_dtypes(include=['object']).columns\n\n# заполняем пропущенные элементы новой категорией, так как у клиентов в тесте может не быть 4 месяца\ndf[categorical_columns] = df[categorical_columns].fillna(\"missing\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Самое главное проследить за изменениями признаков за эти 3 месяца. Создаем таблицу со всеми признаками за каждый месяц.","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# получение только численных признаков\nnumeric_cols = df.drop(columns=['id']).select_dtypes(include=['number']).columns.tolist()\nfor col in numeric_cols:\n    # получением минимального возможного значения признака\n    mean_val = df[col].mean()\n    # заполнение пропущенных значений минимальным значением признака\n    df[col].fillna(mean_val, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Заполняем опять средним. Появились nan так как у клиентов может не быть записи за 4 месяц.","metadata":{}},{"cell_type":"markdown","source":"### Восстановление start_claster с помощью Catboost ","metadata":{"id":"MJdqCgJ0Eht6"}},{"cell_type":"markdown","source":"Catboost лучше всего себя показал и быстрее, что не мало важно. Мы пробовали lightgbm, xgboost, нейронку pytorch, ансамбль из моделей ( Catboost, lightgbm, xgboost).","metadata":{}},{"cell_type":"code","source":"# выделяем тренировочные данные (без пропущенных значений целевой переменной)\ntrain_data = df[df['start_cluster_month_3'] != 'missing'].drop(\n    ['id', 'end_cluster_month_3'], axis=1)\n# выделяем тестовые данные (пропущенные значения целевой переменной)\npredict_data = df[df['start_cluster_month_3'] == 'missing'].drop(\n    ['id', 'end_cluster_month_3'], axis=1)\n\n# получаем признаки для обучения и целевую переменную\nX = train_data.drop('start_cluster_month_3', axis=1)\ny = train_data['start_cluster_month_3']\n\n# разбиваем на подвыборки обучения и тестирования 80/20\nX_train, X_val, y_train, y_val = train_test_split(X, y,\n                                                  test_size=0.2,\n                                                  random_state=42)","metadata":{"id":"j4fOVgfrEht6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Обучение CATBOOST","metadata":{}},{"cell_type":"code","source":"# архитектура модели\ncatboost_model_start_cluster = CatBoostClassifier(\n    iterations=1024,            # кол-во итераций обучения\n    depth=6,                    # рекомендованная глубина модели\n    learning_rate=0.075,        # скорость обучения\n    random_seed=47,             # сид для воспроизводимости результата\n    loss_function='MultiClass', # тип модели или функция ошибки\n    task_type=\"GPU\",            # обучение на видеокарте\n    devices='0',\n    early_stopping_rounds=20    # регуляризация ранней остановкой в случае\n                                # отстутсвия изменения ф. ошибки 20 итераций\n    )","metadata":{"id":"db7G8fEdEht7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_catboost(model: CatBoostClassifier,\n                   x_train: pd.DataFrame, y_train: pd.Series,\n                   x_val: pd.DataFrame, y_val: pd.Series,\n                   cat_names: pd.core.indexes.base.Index,\n                   model_name: str,\n                   verbose_step: int = 100) -> pd.DataFrame:\n    \"\"\"\n    Функция обучения, тестирования и сохранения модели catboost\n\n    args:\n    model (CatBoostClassifier) - модель catboost\n    x_train (pd.DataFrame) - датафрейм для обучения\n    y_train (pd.Series) - целевая переменная в обучении\n    x_val (pd.DataFrame) - датафрейм для тестирования точности модели\n    y_train (pd.Series) - целевая переменная в тестировании\n    cat_names (pd.core.indexes.base.Index) - список категориальных признаков\n    из тренировочного и тестового датафреймов для автоматической предобработки\n    самой моделью\n    model_name (str) - имя модели для сохранения\n    verbose_step (int) - шаг вывода статуса модели\n\n    return:\n    Возвращается важность признаков модели\n    \"\"\"\n    model.fit(\n        x_train, y_train,                   # обучающая выборка\n        cat_features=np.array(cat_names),   # категориальные признаки\n        eval_set=(x_val, y_val),            # тестовая выборка\n        verbose=verbose_step                         # шаг вывода статуса модели\n    )\n    # сохранение модели\n    model.save_model(f'{model_name}.json')\n    # получение важности признаков\n    feature_importance = model.get_feature_importance(prettified=True)\n    return feature_importance","metadata":{"id":"NyS-Y-ZsEht7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# получаем список категориальных признаков\ncat_names = X.select_dtypes(include=['object']).columns\n# обучение модели с получением важности признаков\nfeature_importance = train_catboost(\n    catboost_model_start_cluster, X_train, y_train, X_val, y_val, cat_names,\n    'catboost_model_start_cluster')","metadata":{"id":"j_tSZgRHEht7","outputId":"e4d33bf6-91d4-4234-c753-adcaf4b4a38e","colab":{"base_uri":"https://localhost:8080/"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# предсказываем разные классы из тестовой подвыборки\ny_pred = catboost_model_start_cluster.predict(X_val)\n# статистика точности моделей по разным метрикам\nprint(classification_report(y_val, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Восстанавление 6 месяца из тестовых данных","metadata":{}},{"cell_type":"code","source":"X_predict = predict_data.drop('start_cluster_month_3', axis=1)\npredicted_clusters = catboost_model_start_cluster.predict(X_predict)","metadata":{"id":"8WxyfCGREht7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_clusters_flat = np.ravel(predicted_clusters)\nclass_counts = pd.Series(predicted_clusters_flat).value_counts()\nprint(class_counts)","metadata":{"id":"nkIaLH46EhuA","outputId":"9042c9aa-8ea4-453f-f789-04c8ee20fea4","colab":{"base_uri":"https://localhost:8080/"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_index = 0\n\ndf_restore_start_cluster = df.copy()\nfor index, row in df_restore_start_cluster.iterrows():\n    # Проверяем, содержится ли в столбце 'date' значение 'month6' и id >= 100000\n    if row['id'] >= 200000:\n        # Вставляем значение из серии в столбец 'start_cluster_month_3' текущей строки\n        df_restore_start_cluster.at[index,\n                                    'start_cluster_month_3'] = predicted_clusters[predicted_index][0]\n        # Увеличиваем индекс текущей строки в серии\n        predicted_index += 1","metadata":{"id":"RwhcdndWEhuA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"matching_rows = df_restore_start_cluster[df_restore_start_cluster['id'] >= 200000].loc[(df_restore_start_cluster['start_cluster_month_1'] == df_restore_start_cluster['start_cluster_month_2']) & (\n    df_restore_start_cluster['start_cluster_month_2'] == df_restore_start_cluster['start_cluster_month_3'])]\nmatching_rows","metadata":{"id":"zA3Af03VEhuA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Также как и в train, у нас не у всех клиетов совпадают start_cluster'ы. ","metadata":{}},{"cell_type":"markdown","source":"## Обучение модели <a class=\"anchor\" id=\"first-bullet\"></a>","metadata":{"id":"2tx_7-T_EhuA"}},{"cell_type":"markdown","source":"Также Catboost лучше всего себя показал и быстрее, что не мало важно. Мы пробовали lightgbm, xgboost, нейронку pytorch, ансамбль из моделей ( Catboost, lightgbm, xgboost).","metadata":{}},{"cell_type":"markdown","source":"### Подготовка данных","metadata":{}},{"cell_type":"code","source":"# получаем обратно тренировочный и тестовый датасеты из общего\ntrain_df = df_restore_start_cluster[df_restore_start_cluster['id']< 200000]\ntest_df = df_restore_start_cluster[df_restore_start_cluster['id'] >= 200000]\n# получаем признаки для обучения и целевую переменную\nX = train_df.drop([\"id\", \"end_cluster_month_3\"], axis=1)\ny = train_df[\"end_cluster_month_3\"]\n# разбиваем на подвыборки обучения и тестирования 80/20\nX_train, X_val, y_train, y_val = train_test_split(X, y,\n                                                  test_size=0.2,\n                                                  random_state=42)","metadata":{"id":"QEQefKBqEhuA","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# архитектура модели\ncatboost_model_end_cluster = CatBoostClassifier(\n    iterations=2025,            # кол-во итераций обучения\n    depth=6,                    # рекомендованная глубина модели\n    learning_rate=0.075,        # скорость обучения\n    random_seed=47,             # сид для воспроизводимости результата\n    loss_function='MultiClass', # тип модели или функция ошибки\n    task_type=\"GPU\",            # обучение на видеокарте\n    devices='0',\n    early_stopping_rounds=20    # регуляризация ранней остановкой в случае\n                                # отстутсвия изменения функции ошибки 20\n                                # итераций подряд\n    )","metadata":{"id":"tjny-aQEEhuB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_names = X_train.select_dtypes(include=['object']).columns\n\nfeature_importance = train_catboost(\n    catboost_model_end_cluster, X_train, y_train, X_val, y_val, cat_names,\n    'catboost_model_end_cluster')","metadata":{"id":"LDa_EWaCEhuB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_importance","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# предсказываем разные классы из тестовой подвыборки\ny_pred = catboost_model_end_cluster.predict(X_val)\n# статистика точности моделей по разным метрикам\nprint(classification_report(y_val, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Тестирование модели","metadata":{"id":"3wAjEPGMEhuB"}},{"cell_type":"code","source":"def weighted_roc_auc(y_true, y_pred, labels, weights_dict):\n    unnorm_weights = np.array([weights_dict[label] for label in labels])\n    weights = unnorm_weights / unnorm_weights.sum()\n    classes_roc_auc = roc_auc_score(y_true, y_pred, labels=labels,\n                                    multi_class=\"ovr\", average=None)\n    return sum(weights * classes_roc_auc)","metadata":{"id":"y-GCBMqNEhuB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cluster_weights = pd.read_excel(\"/kaggle/input/alfa-hackaton/cluster_weights.xlsx\").set_index(\"cluster\")\nweights_dict = cluster_weights[\"unnorm_weight\"].to_dict()","metadata":{"id":"rLQOVJRxEhuB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_proba = catboost_model_end_cluster.predict_proba(X_val)\nweighted_roc_auc(y_val, y_pred_proba, catboost_model_end_cluster.classes_, weights_dict)","metadata":{"id":"bhhMj1O5EhuB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Прогноз на тестовой выборке","metadata":{"id":"uWDlTM7IEhuB"}},{"cell_type":"code","source":"sample_submission_df = pd.read_csv(\"/kaggle/input/alfa-hackaton/sample_submission.csv\") # поменять на свой\nlast_m_test_df = test_df\nlast_m_test_df = last_m_test_df.drop([\"id\" , 'end_cluster_month_3'], axis=1)\n\npool2 = Pool(data=last_m_test_df, cat_features=np.array(cat_names))\n\ntest_pred_proba = catboost_model_end_cluster.predict_proba(pool2) # last_m_test_df\ntest_pred_proba_df = pd.DataFrame(test_pred_proba, columns=catboost_model_end_cluster.classes_)\nsorted_classes = sorted(test_pred_proba_df.columns.to_list())\ntest_pred_proba_df = test_pred_proba_df[sorted_classes]\n\nsample_submission_df[sorted_classes] = test_pred_proba_df\nsample_submission_df.to_csv(\"final1.csv\", index=False) # сохранение модели","metadata":{"id":"1KOoKP8MEhuB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission_df","metadata":{"id":"kGLs0mNAEhuB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n## Выводы\n\nМы решали **задачу прогнозирования временного ряда спроса товаров** собственного производства на 14 дней вперёд.\n\nЗаказчиком предоставлены исторические данные о **продажах за 1 год**, а также в закодированном виде товарная иерархия и информация о магазинах.  \nПрогнозировалось **число проданных товаров в штуках  `pr_sales_in_units`** для каждого **SKU/товара** (2050 шт. в обучающей выборке) в каждом из **10 магазинов**.\n\nОсновные **закономерности**, выявленные в результате анализа:\n- ***Годовой тренд***  - спад средних продаж в зимний сезон октябрь-март.\n- ***Недельная сезонность*** - пик продаж в субботу, спад в понедельник.\n- В течение года несколько высоких ***пиков спроса, в основном в районе праздников***. Самые резкие подъёмы продаж в период Нового года и Пасхи. Подъем продаж начинается за несколько дней до.\n- 40,6% записей относятся к продажам по промоакциям. Возможны одновременные продажи товара в одном магазине по промо и без.\n- В данных представлены продукты с ***неполными временными рядами***: продавались только в дни около Пасхи, начали продаваться полгода назад.\n- Во всех магазинах разный ассортимент товаров даже при условии одинаковых характеристик торговой точки.\n- Все мета-признаки как характеристики магазинов и товаров показали влияние на средний спрос\n\nНа основе имеющихся данных **сгенерированы новые признаки:**  \n- Календарные: день недели, число месяца, номер недели, флаг выходного дня (взят из доп. таблицы)\n- Лаговые признаки 1-30 дней\n- Скользящее среднее за 7 и 14 предыдущих дней\n- Кластеризация по характеристикам магазинов и товаров\n    \nЧтобы временные ряды каждой комбинации Магазин-Товар были полными создан новый датасет, в который добавлены отсутствующие даты с нулевыми продажами.\n\n Обучение, валидация и выбор лучшего набора гиперпараметров проводится на **кросс-валидации Walk Forward**: подбор гиперпараметров на фолде проводится на valid-выборке, оценка лучшей модели на фолде на test-выборке.   \nВ итоге выбрана одна модель среди лучших на каждом фолде.\n\n Предсказание спроса обученной моделью делается последовательно на каждый следующий день с промежуточным перерасчётом лаговых признаков (учитывается предсказанное значение спроса в предыдущий день).\n\nМетрика качества  **ROC-AUC**.  \n\nЛучший результат по качеству и скорости показала модель градиентного бустинга **Catboost**.  <br>\nПолученный результат: ROC-AUC = **0.903898**, на всей выборке. <br>\nПолученный результат: ROC-AUC = **0.896941145**, на паблик выборке (1 место).\n\n\n\n","metadata":{"id":"1CVKrRkWEhuB"}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}