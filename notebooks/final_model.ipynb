{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cодержание:\n",
    "* [First Bullet Header](#first-bullet)\n",
    "* [Second Bullet Header](#second-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Команда: Бета Банк \n",
    "\n",
    "\n",
    "**Цель:** Создать CLTV модель, которая будет выдавать вероятности перехода в каждый из 17 продуктовых кластеров в течение 12 месяцев.\n",
    "\n",
    "Альфа-Банком предоставлены следующие **данные**, описание из файла **feature_description.xlsx**:\n",
    "\n",
    "-   **`train_data.pqt`и `test_data.pqt` – данные о клиентах за 3 месяца:**\n",
    "   \n",
    "    Возможно тут описание длатасета\n",
    "    - `st_id` – захэшированное id магазина;\n",
    "    - `pr_sku_id` – захэшированное id товара;\n",
    "    - `date` – дата;\n",
    "    - `pr_sales_type_id` – флаг наличия промо;\n",
    "    - `pr_sales_in_units` – число проданных товаров без признака промо;\n",
    "    - `pr_promo_sales_in_units` – число проданных товаров с признаком промо;\n",
    "    - `pr_sales_in_rub` – продажи без признака промо в РУБ;\n",
    "    - `pr_promo_sales_in_rub` – продажи с признаком промо в РУБ;\n",
    "\n",
    "\n",
    "  \n",
    "Метрикой качества выступает **ROC-AUC**.\n",
    "\n",
    "Данные о клиентах и масскированы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Необходимые библиотеки\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "import warnings\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "import os\n",
    "from sklearn.utils import resample\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "# import optuna\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "pd.set_option('display.max_rows', 93)\n",
    "\n",
    "# Отключить все предупреждения временно\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание \n",
    "\n",
    "1. Качественно оформите код модели\n",
    "2. Доработка решения на платформе будет открыта до 18 апреля 12:00\n",
    "3. Обязательно наличие .README;\n",
    "4. Код должен быть читабелен и понятен;\n",
    "5. Решение должно быть воспроизводимо: эксперты должны иметь возможность протестировать ваше решение на финале."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка и изучение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Функция для чтения DataFrame из Parquet-файла.\n",
    "\n",
    "    Параметры:\n",
    "    path (str): Путь к Parquet-файлу.\n",
    "\n",
    "    Возвращает:\n",
    "    pd.DataFrame: DataFrame, прочитанный из Parquet-файла.\n",
    "\n",
    "    \"\"\"\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_parquet(path)\n",
    "        print(f'Успешно: Данные {path} загружены')\n",
    "        return df\n",
    "    else:\n",
    "        print(f'Ошибка: {path} не найден')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Успешно: Данные ../data/raw/train_data.pqt загружены\n",
      "Успешно: Данные ../data/raw/test_data.pqt загружены\n"
     ]
    }
   ],
   "source": [
    "# Путь до файла train_df\n",
    "path_train_df = \"../data/raw/train_data.pqt\"\n",
    "\n",
    "# Путь до файла test_df\n",
    "path_test_df = \"../data/raw/test_data.pqt\"\n",
    "\n",
    "train_df = read_df(path=path_train_df)\n",
    "test_df = read_df(path=path_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Объединение датасетов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_df, test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "Тут кратко описание секции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  AVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень много плохих столбцов sum но  cnt хорошие и можно сгенирировать avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_a_oper_1m'] = df['sum_a_oper_1m'] / df['cnt_a_oper_1m']\n",
    "df['avg_b_oper_1m'] = df['sum_b_oper_1m'] / df['cnt_b_oper_1m']\n",
    "df['avg_c_oper_1m'] = df['sum_c_oper_1m'] / df['cnt_c_oper_1m']\n",
    "\n",
    "df['avg_deb_d_oper_1m'] = df['sum_deb_d_oper_1m'] / df['cnt_deb_d_oper_1m']\n",
    "df['avg_cred_d_oper_1m'] = df['sum_cred_d_oper_1m'] / df['cnt_cred_d_oper_1m']\n",
    "\n",
    "df['avg_deb_e_oper_1m'] = df['sum_deb_e_oper_1m'] / df['cnt_deb_e_oper_1m']\n",
    "df['avg_cred_e_oper_1m'] = df['sum_cred_e_oper_1m'] / df['cnt_cred_e_oper_1m']\n",
    "\n",
    "\n",
    "df['avg_deb_f_oper_1m'] = df['sum_deb_f_oper_1m'] / df['cnt_deb_f_oper_1m']\n",
    "df['avg_cred_f_oper_1m'] = df['sum_cred_f_oper_1m'] / df['cnt_cred_f_oper_1m']\n",
    "\n",
    "df['avg_deb_g_oper_1m'] = df['sum_deb_g_oper_1m'] / df['cnt_deb_g_oper_1m']\n",
    "df['avg_cred_g_oper_1m'] = df['sum_cred_g_oper_1m'] / df['cnt_cred_g_oper_1m']\n",
    "\n",
    "df['avg_deb_h_oper_1m'] = df['sum_deb_h_oper_1m'] / df['cnt_deb_h_oper_1m']\n",
    "df['avg_cred_h_oper_1m'] = df['sum_cred_h_oper_1m'] / df['cnt_cred_h_oper_1m']\n",
    "\n",
    "\n",
    "df['avg_a_oper_3m'] = df['sum_a_oper_3m'] / df['cnt_a_oper_3m']\n",
    "df['avg_b_oper_3m'] = df['sum_b_oper_3m'] / df['cnt_b_oper_3m']\n",
    "df['avg_c_oper_3m'] = df['sum_c_oper_3m'] / df['cnt_c_oper_3m']\n",
    "\n",
    "df['avg_deb_d_oper_3m'] = df['sum_deb_d_oper_3m'] / df['cnt_deb_d_oper_3m']\n",
    "df['avg_cred_d_oper_3m'] = df['sum_cred_d_oper_3m'] / df['cnt_cred_d_oper_3m']\n",
    "\n",
    "df['avg_deb_e_oper_3m'] = df['sum_deb_e_oper_3m'] / df['cnt_deb_e_oper_3m']\n",
    "df['avg_cred_e_oper_3m'] = df['sum_cred_e_oper_3m'] / df['cnt_cred_e_oper_3m']\n",
    "\n",
    "df['avg_deb_f_oper_3m'] = df['sum_deb_f_oper_3m'] / df['cnt_deb_f_oper_3m']\n",
    "df['avg_cred_f_oper_3m'] = df['sum_cred_f_oper_3m'] / df['cnt_cred_f_oper_3m']\n",
    "\n",
    "df['avg_deb_g_oper_3m'] = df['sum_deb_g_oper_3m'] / df['cnt_deb_g_oper_3m']\n",
    "df['avg_cred_g_oper_3m'] = df['sum_cred_g_oper_3m'] / df['cnt_cred_g_oper_3m']\n",
    "\n",
    "df['avg_deb_h_oper_3m'] = df['sum_deb_h_oper_3m'] / df['cnt_deb_h_oper_3m']\n",
    "df['avg_cred_h_oper_3m'] = df['sum_cred_h_oper_3m'] / df['cnt_cred_h_oper_3m']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Удаление плохих столбцов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Буду пробовать не удалять"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    'balance_amt_max',\n",
    "    'balance_amt_min',\n",
    "    'balance_amt_day_avg',\n",
    "    'index_city_code',\n",
    "    'max_founderpres',\n",
    "    'min_founderpres',\n",
    "    'ogrn_exist_months',\n",
    "    'sum_a_oper_1m',\n",
    "    'sum_b_oper_1m',\n",
    "    'sum_c_oper_1m',\n",
    "    'sum_deb_d_oper_1m',\n",
    "    'sum_cred_d_oper_1m',\n",
    "    'sum_deb_e_oper_1m',\n",
    "    'sum_cred_e_oper_1m',\n",
    "    'sum_deb_f_oper_1m',\n",
    "    'sum_cred_f_oper_1m',\n",
    "    'sum_deb_g_oper_1m',\n",
    "    'sum_cred_g_oper_1m',\n",
    "    'sum_deb_h_oper_1m',\n",
    "    'sum_cred_h_oper_1m',\n",
    "    'sum_a_oper_3m',\n",
    "    'sum_b_oper_3m',\n",
    "    'sum_c_oper_3m',\n",
    "    'sum_deb_d_oper_3m',\n",
    "    'sum_cred_d_oper_3m',\n",
    "    'sum_deb_e_oper_3m',\n",
    "    'sum_cred_e_oper_3m',\n",
    "    'sum_deb_f_oper_3m',\n",
    "    'sum_cred_f_oper_3m',\n",
    "    'sum_deb_g_oper_3m',\n",
    "    'sum_cred_g_oper_3m',\n",
    "    'sum_deb_h_oper_3m',\n",
    "    'sum_cred_h_oper_3m']\n",
    "\n",
    "\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Восстановление категориальных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns_to_restore = ['channel_code', 'city',\n",
    "                          'city_type', 'ogrn_month', 'ogrn_year', 'okved', 'segment']\n",
    "\n",
    "for column in cat_columns_to_restore:\n",
    "  df[column] = df.groupby('id')[column].apply(\n",
    "      lambda x: restore_cal(x)).reset_index()[column]\n",
    "  print(f\"Колонка - {column} - восстановлена\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание таблицы с 3 месяцами "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = df.pivot_table(index='id', columns='date', aggfunc='first')\n",
    "\n",
    "# Преобразуем мультииндексные столбцы в одноуровневые\n",
    "pivot_df.columns = [f'{col[0]}_{col[1]}' for col in pivot_df.columns]\n",
    "\n",
    "# Объединяем строки для каждого клиента в одну\n",
    "pivot_df.reset_index(inplace=True)\n",
    "pivot_df = pivot_df.drop(\n",
    "    columns=['end_cluster_month_1', 'end_cluster_month_2'], axis=0)\n",
    "\n",
    "df = pivot_df\n",
    "\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "df[categorical_columns] = df[categorical_columns].fillna(\"missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Воостановление start_claster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df[df['start_cluster_month_3'] != 'missing'].drop(\n",
    "    ['id',  'end_cluster_month_3'], axis=1)\n",
    "predict_data = df[df['start_cluster_month_3'] == 'missing'].drop(\n",
    "    ['id', 'end_cluster_month_3'], axis=1)\n",
    "\n",
    "X = train_data.drop('start_cluster_month_3', axis=1)\n",
    "y = train_data['start_cluster_month_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(iterations=2028,\n",
    "                           depth=8,\n",
    "                           learning_rate=0.075,\n",
    "                           random_seed=47,\n",
    "                           loss_function='MultiClass',\n",
    "                           task_type=\"GPU\",\n",
    "                           devices='0',\n",
    "                           early_stopping_rounds=20\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_catboost(model, x_train, y_train, x_val, y_val, cat_names):\n",
    "\n",
    "    model.fit(\n",
    "        x_train, y_train,\n",
    "        cat_features=np.array(cat_names),\n",
    "        eval_set=(x_val, y_val),\n",
    "        verbose=100  # через сколько итераций выводить стату\n",
    "    )\n",
    "    model.save_model('catboost_model_start_claster.json')  # сохранение модели\n",
    "    feature_importance = model.get_feature_importance(\n",
    "        prettified=True)  # датасет с важностью признаков\n",
    "\n",
    "    return feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = train_catboost(\n",
    "    model, X_train, y_train, X_val, y_val, cat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_predict = predict_data.drop('start_cluster_month_3', axis=1)\n",
    "predicted_clusters = model.predict(X_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_index = 0\n",
    "\n",
    "df_restore_start_cluster = df.copy()\n",
    "for index, row in df_restore_start_cluster.iterrows():\n",
    "    # Проверяем, содержится ли в столбце 'date' значение 'month6' и id >= 100000\n",
    "    if row['id'] >= 200000:\n",
    "        # Вставляем значение из серии в столбец 'start_cluster_month_3' текущей строки\n",
    "        df_restore_start_cluster.at[index,\n",
    "                                    'start_cluster_month_3'] = predicted_clusters[predicted_index][0]\n",
    "        # Увеличиваем индекс текущей строки в серии\n",
    "        predicted_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_rows = df[df['id'] >= 200000].loc[(df_restore_start_cluster['start_cluster_month_1'] == df_restore_start_cluster['start_cluster_month_2']) & (\n",
    "    df_restore_start_cluster['start_cluster_month_2'] == df_restore_start_cluster['start_cluster_month_3'])]\n",
    "matching_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели <a class=\"anchor\" id=\"first-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Выводы и резюме\n",
    "\n",
    "Мы решали **задачу прогнозирования временного ряда спроса товаров** собственного производства на 14 дней вперёд. \n",
    "\n",
    "Заказчиком предоставлены исторические данные о **продажах за 1 год**, а также в закодированном виде товарная иерархия и информация о магазинах.  \n",
    "Прогнозировалось **число проданных товаров в штуках  `pr_sales_in_units`** для каждого **SKU/товара** (2050 шт. в обучающей выборке) в каждом из **10 магазинов**.\n",
    "\n",
    "Основные **закономерности**, выявленные в результате анализа: \n",
    "- ***Годовой тренд***  - спад средних продаж в зимний сезон октябрь-март.\n",
    "- ***Недельная сезонность*** - пик продаж в субботу, спад в понедельник.\n",
    "- В течение года несколько высоких ***пиков спроса, в основном в районе праздников***. Самые резкие подъёмы продаж в период Нового года и Пасхи. Подъем продаж начинается за несколько дней до.\n",
    "- 40,6% записей относятся к продажам по промоакциям. Возможны одновременные продажи товара в одном магазине по промо и без. \n",
    "- В данных представлены продукты с ***неполными временными рядами***: продавались только в дни около Пасхи, начали продаваться полгода назад.\n",
    "- Во всех магазинах разный ассортимент товаров даже при условии одинаковых характеристик торговой точки.\n",
    "- Все мета-признаки как характеристики магазинов и товаров показали влияние на средний спрос\n",
    "\n",
    "На основе имеющихся данных **сгенерированы новые признаки:**  \n",
    "- Календарные: день недели, число месяца, номер недели, флаг выходного дня (взят из доп. таблицы)\n",
    "- Лаговые признаки 1-30 дней\n",
    "- Скользящее среднее за 7 и 14 предыдущих дней\n",
    "- Кластеризация по характеристикам магазинов и товаров\n",
    "    \n",
    "Чтобы временные ряды каждой комбинации Магазин-Товар были полными создан новый датасет, в который добавлены отсутствующие даты с нулевыми продажами.\n",
    "\n",
    " Обучение, валидация и выбор лучшего набора гиперпараметров проводится на **кросс-валидации Walk Forward**: подбор гиперпараметров на фолде проводится на valid-выборке, оценка лучшей модели на фолде на test-выборке.   \n",
    "В итоге выбрана одна модель среди лучших на каждом фолде.\n",
    "\n",
    " Предсказание спроса обученной моделью делается последовательно на каждый следующий день с промежуточным перерасчётом лаговых признаков (учитывается предсказанное значение спроса в предыдущий день).\n",
    "\n",
    " Для оценки модели использовалась метрика качества  **WAPE**, посчитанная на уровне Магазин-Товар-Дата.  \n",
    " \n",
    "Лучший результат по качеству и скорости показала модель градиентного бустинга **LightGBM**.  <br>\n",
    "Полученный результат: WAPE = **0,47**, превышает baseline (предсказание последним известным значением) с метрикой 69%.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
